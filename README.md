# Predicting Graduateâ€‘Program Placement Success

> **ENSFâ€¯544 â€¢ Machineâ€‘Learning Capstone**  
> **Author:** **Shamisâ€¯Ali** (30096335)

---

## ğŸ—’ï¸ Overview
Recruitment agency **Powerâ€¯Recruitment** (Bloomington,â€¯IN) wants to estimate before investing in a client, whether that applicant will ultimately secure a U.S. graduateâ€‘program placement.  
Using the **Jobâ€¯Placement Dataset** from Kaggle, this project:

1. Cleans & encodes the raw CSV.  
2. Benchmarks three supervised models (Logisticâ€¯Regression, Randomâ€¯Forest, SVM).  
3. Outputs probability scores that the agency can embed in its internal CRM.

---

---

## ğŸ“ˆ Dataset

| Column            | Description                                   |
|-------------------|-----------------------------------------------|
| `gender`          | Male / Female                                 |
| `age`             | Age in years                                  |
| `stream`          | Undergraduate discipline                      |
| `university`      | Undergraduate institution                     |
| `gpa`             | GPA (4â€‘point scale)                           |
| `work_experience` | Prior industry experience (Yes/No)            |
| `placement_status`| **Target** â€“ Placed / Not Placed              |
| `salary`          | Starting salary in USD if placed (NaN else)   |

*Source: Kaggleâ€¯â€”â€¯â€œJobâ€¯Placementâ€¯Datasetâ€ (downloadedâ€¯2025â€‘05â€‘05).*
Dataset Link: https://www.kaggle.com/datasets/mahad049/job-placement-dataset/data

---

## ğŸš€ Quickstart

```bash
# clone & create Python env
git clone https://github.com/<yourâ€‘handle>/placementâ€‘success.git
cd placementâ€‘success
python -m venv .venv
source .venv/bin/activate           # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

# fetch the data
kaggle datasets download -d mahad049/job-placement-dataset -p data/ --unzip

# reproduce every figure & metric
jupyter lab notebooks/Project-544.ipynb
```

Prefer a CLI workflow?

```bash
python src/train.py --model random_forest --save reports/rf.pkl
```

---

## ğŸ› ï¸ Methodology

| Stage               | Tooling / Techniques                                          |
|---------------------|---------------------------------------------------------------|
| **Cleaning & EDA**  | `pandas`, missingâ€‘value charts, pairâ€‘plots                    |
| **Feature Eng.**    | Oneâ€‘hot encoding (`sklearn.compose.ColumnTransformer`)        |
| **Modeling**        | Logisticâ€¯Regression, Randomâ€¯Forest, SVM (RBF kernel)          |
| **Hyperâ€‘params**    | `GridSearchCV`, 5â€‘fold CV, `scoring='accuracy'`               |
| **Evaluation**      | Train vs CV vs Test accuracy, precision, recall, F1, ROCâ€‘AUC  |
| **Visuals**         | Learning curves, ROC curves, confusion matrices (`matplotlib`)|

Full commentary lives in **`notebooks/Projectâ€‘544.ipynb`**.

---

## ğŸ“Š Results

| Model                | Trainâ€¯Acc | CVâ€¯Acc | Testâ€¯Acc | F1â€‘score |
|----------------------|:---------:|:------:|:--------:|:--------:|
| LogisticÂ Regression  | 0.99 | 0.98 | 0.96 | 0.96 |
| RandomÂ Forest        | 0.99 | 0.98 | **0.97** | **0.97** |
| SVMÂ (RBF)            | 0.98 | 0.98 | 0.96 | 0.96 |

*Randomâ€¯Forest produced the best generalization: **97â€¯% test accuracy** and the top F1.*  
Confusion matrices and ROC curves are available in `reports/figures/`.

---

## ğŸ”„ Reproducibility
* **PythonÂ 3.11**  
* Deterministic splits & model seeds (`random_state=42`)  
* Exact versions pinned in `requirements.txt`.

---

## ğŸ“… Roadmap
- **Probability calibration** (Platt or isotonic) for better rankâ€‘ordering.  
- **Gradientâ€‘boosting benchmarks** (XGBoost / LightGBM).  
- **Streamlit app** to score candidates interactively.  
- **New data collection** (2024â€‘2025 cohort) to mitigate temporal drift.

---

## ğŸ¤ Contributing
1. Fork â†’ branch â†’ PR.  
2. Follow PEPâ€¯8 & run `pytest`.  
3. Be excellent to each other (see `CODE_OF_CONDUCT.md`).

---

## ğŸ“° License
**Code:** MIT  
**Data:** CC0â€¯1.0 (Kaggle dataset author)
